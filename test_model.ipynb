{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6c9056b-4bce-458d-b1b1-d25c88fafdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNN Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from metrics import *\n",
    "from data_prepare import final_testloader\n",
    "from models import GCNN, AttGNN, GCNN_mutual_attention, GCNN_desc_pool, GCNN_with_descriptors\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.cuda(\"cpu\")\n",
    "# model = GCNN_mutual_attention(num_layers=1, dropout=0.3)\n",
    "# model.load_state_dict(torch.load(\"../masif_features/GCN.pth\"))\n",
    "\n",
    "# model = GCNN()\n",
    "# model.load_state_dict(torch.load(\"../masif_features/GCN_baseline.pth\"))\n",
    "\n",
    "# model = GCNN_desc_pool()\n",
    "# model.load_state_dict(torch.load(\"../masif_features/GCN_pool.pth\"))\n",
    "\n",
    "model = GCNN_with_descriptors(num_layers=1, dropout=0.3, num_features_pro=1024, output_dim=128, descriptor_dim=80, transformer_dim=31, nhead=4, dim_feedforward=128)\n",
    "model.load_state_dict(torch.load(\"../masif_features/GCN_03_double_transforer.pth\"))\n",
    "\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78d1ae94-6d59-43cb-aa89-b9c5ee1ebe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np \n",
    "import random\n",
    "import math\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from torch.utils.data import Dataset as Dataset_n\n",
    "from torch_geometric.data import DataLoader as DataLoader_n\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# npy_file = \"../masif_features/testset.npy\"\n",
    "# processed_dir=\"../masif_features/processed/\"\n",
    "# def bump(g):\n",
    "#     return g\n",
    "#     # return Data.from_dict(g.__dict__)\n",
    "\n",
    "# class LabelledDataset(Dataset_n):\n",
    "#     def __init__(self, npy_file, processed_dir):\n",
    "#       self.npy_ar = np.load(npy_file)\n",
    "#       self.processed_dir = processed_dir\n",
    "#       self.protein_1 = self.npy_ar[:,2]\n",
    "#       self.protein_2 = self.npy_ar[:,5]\n",
    "#       self.label = self.npy_ar[:,6].astype(float)\n",
    "#       self.n_samples = self.npy_ar.shape[0]\n",
    "\n",
    "#     def __len__(self):\n",
    "#       return(self.n_samples)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#       prot_1 = os.path.join(self.processed_dir, self.protein_1[index]+\".pt\")\n",
    "#       prot_2 = os.path.join(self.processed_dir, self.protein_2[index]+\".pt\")\n",
    "#       # print(prot_1, prot_2)\n",
    "#       # print(glob.glob(prot_1), glob.glob(prot_2))\n",
    "#       #print(f'Second prot is {prot_2}')\n",
    "#       prot_1 = torch.load(glob.glob(prot_1)[0], weights_only=True)\n",
    "#       #print(f'Here lies {glob.glob(prot_2)}')\n",
    "#       prot_2 = torch.load(glob.glob(prot_2)[0], weights_only=True)\n",
    "#       prot_1 = bump(prot_1)\n",
    "#       prot_2 = bump(prot_2)\n",
    "#       prot_1.x = prot_1.x.to(torch.float32)\n",
    "#       prot_2.x = prot_2.x.to(torch.float32)\n",
    "#       return prot_1, prot_2, torch.tensor(self.label[index])\n",
    "\n",
    "\n",
    "\n",
    "# dataset = LabelledDataset(npy_file = npy_file ,processed_dir= processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc16d48e-c071-43f4-8685-fbb1d62374d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = final_testloader # DataLoader_n(dataset=final_testset, batch_size=4, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe01962a-d8bb-46cf-82af-bf74a2f2ad2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4f8f5a4bc04d75b38948bd2d7128e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from metrics import *\n",
    "from models import GCNN, AttGNN, GCNN_mutual_attention\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.cuda(\"cpu\")\n",
    "# model = GCNN_mutual_attention(dropout=0.3, num_layers=1)\n",
    "# model.load_state_dict(torch.load(\"../masif_features/GCN.pth\")) #path to load the model\n",
    "# model.to(device)\n",
    "# model.eval()\n",
    "predictions = torch.Tensor()\n",
    "labels = torch.Tensor()\n",
    "with torch.no_grad():\n",
    "    for prot_1, prot_2, label, mas1_straight, mas1_flipped, mas2_straight, mas2_flipped in tqdm(testloader):\n",
    "      prot_1 = prot_1.to(device)\n",
    "      prot_2 = prot_2.to(device)\n",
    "      #print(\"H\")\n",
    "      #print(torch.Tensor.size(prot_1.x), torch.Tensor.size(prot_2.x))\n",
    "      mas1_straight = mas1_straight.to(device)\n",
    "      mas1_flipped = mas1_flipped.to(device)\n",
    "      mas2_straight = mas2_straight.to(device)\n",
    "      mas2_flipped = mas2_flipped.to(device)\n",
    "      output = model(prot_1, prot_2, mas1_straight, mas1_flipped, mas2_straight, mas2_flipped)\n",
    "      predictions = torch.cat((predictions, output.cpu()), 0)\n",
    "      labels = torch.cat((labels, label.view(-1,1).cpu()), 0)\n",
    "labels = labels.numpy().flatten()\n",
    "predictions = predictions.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f8ed785-cc9a-4ea2-a508-34057c01e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse : 36.4664192199707\n",
      "Accuracy : 89.48190575370997\n",
      "precision: 0.8843861740166865\n",
      "Sensititvity :0.9199107364244979\n",
      "specificity : 0.8670868731159221\n",
      "f-score : 0.9017987360233348\n",
      "MCC : 0.7893734218370622\n",
      "AUROC: 0.9553775215801509\n",
      "AUPRC: 0.9539667799833158\n"
     ]
    }
   ],
   "source": [
    "mse = get_mse(labels, predictions)\n",
    "acc = get_accuracy(labels, predictions, 0.5)\n",
    "prec = precision(labels, predictions, 0.5)\n",
    "sensitivity = sensitivity(labels, predictions,  0.5)\n",
    "specificity = specificity(labels, predictions, 0.5)\n",
    "f1 = f_score(labels, predictions, 0.5)\n",
    "mcc = mcc(labels, predictions,  0.5)\n",
    "auroc = auroc(labels, predictions)\n",
    "auprc = auprc(labels, predictions)\n",
    "\n",
    "\n",
    "print(f'mse : {mse}')\n",
    "print(f'Accuracy : {acc}')\n",
    "print(f'precision: {prec}')\n",
    "print(f'Sensititvity :{sensitivity}')\n",
    "print(f'specificity : {specificity}')\n",
    "print(f'f-score : {f1}')\n",
    "print(f'MCC : {mcc}')\n",
    "print(f'AUROC: {auroc}')\n",
    "print(f'AUPRC: {auprc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9e17770-c059-4d59-af3f-0d61805f0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import traceback\n",
    "from copy import deepcopy\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "ID = '[2]'\n",
    "\n",
    "def alarm_message(message: str) -> None:\n",
    "    \"\"\"Отправляем message в @alarm_bot\"\"\"\n",
    "    alarm = 'https://alarmerbot.ru/'\n",
    "    key = \"b2b834-4b2bae-6ebc49\"\n",
    "    try:\n",
    "        requests.post(alarm, data={'key': key, 'message': ID + ' ' + message})\n",
    "    except Exception as ex:\n",
    "        print('alarm error for {}: {}'.format(key, str(type(ex))))\n",
    "\n",
    "\n",
    "# last_len = len(open('logging.txt', 'r').readlines())\n",
    "\n",
    "# while True:\n",
    "#     cur = open('logging.txt', 'r').readlines()\n",
    "#     if len(cur) > last_len:\n",
    "#         for line in cur[last_len:]:\n",
    "#             alarm_message(line)\n",
    "#         last_len = len(cur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e96ee12e-84e3-4fc8-904f-4b3897f3fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_message('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b051064-d14d-4fec-9d93-8ab48be06ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92b021-d771-4c59-a585-3405cb5eabbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2828bd-3c38-43cb-9297-852d1984cdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b2bc3-b266-4900-a686-0aae9934c822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
