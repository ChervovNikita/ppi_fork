{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "929c25f3-30cd-4360-b4bb-603bc0575d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f6cb80c-bd0e-4212-a0b4-ee1334bbcc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np \n",
    "import random\n",
    "import math\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from torch.utils.data import Dataset as Dataset_n\n",
    "from torch_geometric.data import DataLoader as DataLoader_n\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def bump(g):\n",
    "    return g\n",
    "    # return Data.from_dict(g.__dict__)\n",
    "\n",
    "class LabelledDataset(Dataset_n):\n",
    "    def __init__(self, npy_file, processed_dir):\n",
    "      self.npy_ar = np.load(npy_file)\n",
    "      self.processed_dir = processed_dir\n",
    "      self.protein_1 = self.npy_ar[:,2]\n",
    "      self.protein_2 = self.npy_ar[:,5]\n",
    "      self.label = self.npy_ar[:,6].astype(float)\n",
    "      self.n_samples = self.npy_ar.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "      return(self.n_samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "      prot_1 = os.path.join(self.processed_dir, self.protein_1[index]+\".pt\")\n",
    "      prot_2 = os.path.join(self.processed_dir, self.protein_2[index]+\".pt\")\n",
    "      prot_1 = torch.load(glob.glob(prot_1)[0])['mean_representations'][33]\n",
    "      prot_2 = torch.load(glob.glob(prot_2)[0])['mean_representations'][33]\n",
    "      prot_1 = bump(prot_1)\n",
    "      prot_2 = bump(prot_2)\n",
    "      return prot_1, prot_2, torch.tensor(self.label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceb515e1-3224-4f68-9f80-062434ac0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_file = \"../human_features/npy_file_new(human_dataset).npy\"\n",
    "npy_file_test = \"../human_features/npy_file_new(human_dataset)_test.npy\"\n",
    "processed_dir=\"../human_features/esm/\"\n",
    "# train = LabelledDataset(npy_file=npy_file, processed_dir=processed_dir)\n",
    "# test = LabelledDataset(npy_file=npy_file_test, processed_dir=processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c96aa9-c61f-4519-bcd5-01ce9c6e314a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b209a29353614c8383c49ec602aee7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "mapping_train = np.load(npy_file)\n",
    "bad_rows = []\n",
    "for row in tqdm(mapping_train):\n",
    "    try:\n",
    "        _, _, prot1, _, _, prot2, label = row\n",
    "        prot_1 = os.path.join(processed_dir, prot1+\".pt\")\n",
    "        prot_2 = os.path.join(processed_dir, prot2+\".pt\")\n",
    "        prot_1 = torch.load(glob.glob(prot_1)[0])['mean_representations'][33]\n",
    "        prot_2 = torch.load(glob.glob(prot_2)[0])['mean_representations'][33]\n",
    "        p = torch.cat([prot_1, prot_2])\n",
    "        label = float(label)\n",
    "        X_train.append(p)\n",
    "        y_train.append(label)\n",
    "    except:\n",
    "        bad_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4c0e6a8-3a60-434c-a58f-de53d809f62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20815d427dd4e5283a38a0d04713422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5677 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "bad_test_rows = []\n",
    "mapping_test = np.load(npy_file_test)\n",
    "for row in tqdm(mapping_test):\n",
    "    try:\n",
    "        _, _, prot1, _, _, prot2, label = row\n",
    "        prot_1 = os.path.join(processed_dir, prot1+\".pt\")\n",
    "        prot_2 = os.path.join(processed_dir, prot2+\".pt\")\n",
    "        prot_1 = torch.load(glob.glob(prot_1)[0])['mean_representations'][33]\n",
    "        prot_2 = torch.load(glob.glob(prot_2)[0])['mean_representations'][33]\n",
    "        p = torch.cat([prot_1, prot_2])\n",
    "        label = float(label)\n",
    "        X_test.append(p)\n",
    "        y_test.append(label)\n",
    "    except:\n",
    "        bad_test_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36eae427-9982-4232-a803-3824b527e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    X_train[i] = X_train[i][None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551e20c1-7fae-4d0a-9639-549403b70e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.cat(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed6778bf-dfe8-4efb-b105-2f0f925a17e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -qq scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "312f6d03-ca8d-49b7-9ebb-967b1715cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val, ytrain, yval = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fd5cc1b-ecf9-4f35-8fc3-375d767de9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = [x for x in ytrain]\n",
    "yval = [x for x in yval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "677b9fca-2b3e-422b-ba37-1e8e39414b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_524/3616782837.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_torch = torch.tensor(X_train, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de62959b0353420bbd61888fe539b47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example predictions: tensor([0.4317, 0.5838, 0.2083, 0.3097, 0.2952, 0.3907, 0.2535, 0.3899, 0.3198,\n",
      "        0.4608])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_train_torch = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_torch = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=X_train.shape[1], out_features=1)\n",
    ")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch).squeeze()\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(X_train_torch).squeeze(dim=1)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    print(\"Example predictions:\", probs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eb89378-e51a-4edf-864f-ff24381334f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def validate_model_mse(val_features, val_probs, model):\n",
    "    X_val_torch = torch.tensor(val_features, dtype=torch.float32)\n",
    "    y_val_torch = torch.tensor(val_probs, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_val_torch).squeeze(dim=1)\n",
    "        preds = torch.sigmoid(logits)\n",
    "        mse_value = ((preds - y_val_torch) ** 2).mean()\n",
    "    print(f\"Validation MSE: {mse_value.item():.6f}\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bc6a7b9-cfcf-43cb-851c-92c376b32edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_524/3830430384.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_torch = torch.tensor(val_features, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.021742\n"
     ]
    }
   ],
   "source": [
    "validate_model_mse(val, yval, model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91805e2c-ba90-4b91-94fd-fc549052921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_test)):\n",
    "    X_test[i] = X_test[i][None, :]\n",
    "X_test = torch.cat(X_test)\n",
    "y_test = [x for x in y_test]\n",
    "\n",
    "X_test = X_test.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1c87326-2e04-41df-bf51-b00c82e7e968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.027581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_524/3830430384.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_torch = torch.tensor(val_features, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "validate_model_mse(X_test, y_test, model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831fa67-8cc1-4932-a76f-70b2c20c7d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd404cc-44cb-470c-8afa-c0e3f2d87673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192d40e-bb49-4f20-b43a-f00f24c19616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc782c-f1ec-46aa-9514-f83f78996bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29bf59b-0570-45ba-b8ca-c3928f8be071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2c1ed-3ba2-4808-924e-c5cedabc9139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489fd613-f27f-4514-81e4-2a7f08734fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f7a6c-4e6f-4916-9f75-f7cff8955982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ebd27fe-f0bb-401e-b346-9e7eef1d6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5dcb160c-b4f5-4db9-9cf6-10a9e8c06f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(train, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74a98096-2a65-4abd-97e1-334c99d7d30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9602628763564114"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(yval, logreg.predict(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6cb844b6-2bd5-4ec2-8252-3903bf2f3b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b45899ed-6269-4ed9-9806-41337c29a5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "413dcad7-4057-4f3a-8605-668552265d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393564356435643"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, logreg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3f8da981-5fe3-4c7a-b514-789a81903ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 5203, False: 453})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "37c87515-0ce5-4163-9256-1be24f6369b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9199080622347949"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5203 / (453 + 5203) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b818f-f7f7-4ba1-9119-9be999666bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c619c3-d9e2-4f0b-8ab3-a75fe71fe56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e90d7-7f0f-4200-b03a-182a1fb2f656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee37137-b5ca-4062-9acf-7aac1dc2da20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
