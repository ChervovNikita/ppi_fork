{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def split_pdb_by_chains(pdb_path, output_dir):\n",
    "    \"\"\"\n",
    "    Splits a PDB file into multiple files, each containing one chain.\n",
    "\n",
    "    :param pdb_path: Path to the input PDB file.\n",
    "    :param output_dir: Directory where the output files will be saved.\n",
    "    \"\"\"\n",
    "    # Read the PDB file\n",
    "    with open(pdb_path, 'r') as pdb_file:\n",
    "        lines = pdb_file.readlines()\n",
    "\n",
    "    # Dictionary to hold lines for each chain\n",
    "    chains = defaultdict(list)\n",
    "\n",
    "    # Iterate through the lines and group by chain\n",
    "    for line in lines:\n",
    "        if line.startswith(\"ATOM\") or line.startswith(\"HETATM\"):\n",
    "            chain_id = line[21]  # Chain identifier is at index 21\n",
    "            chains[chain_id].append(line)\n",
    "\n",
    "    # Write each chain to a separate file\n",
    "    for chain_id, chain_lines in chains.items():\n",
    "        output_path = f\"{output_dir}/{file.split('.')[0]}_{chain_id}.pdb\"\n",
    "        with open(output_path, 'w') as output_file:\n",
    "            output_file.writelines(chain_lines)\n",
    "        # print(f\"Wrote {chain_id} written to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [00:03<00:00, 94.39it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pdb_dir = '../pdb_test_2_merged'\n",
    "files = os.listdir(pdb_dir)\n",
    "print(len(files))\n",
    "\n",
    "out_dir = '../pdb_chains_new_test'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for file in tqdm(files):\n",
    "    split_pdb_by_chains(f'{pdb_dir}/{file}', out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/7193 [00:00<01:06, 107.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7193/7193 [01:21<00:00, 87.86it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pdb_dir = '../data_preparation/good_positives_pdb_06may'\n",
    "files = os.listdir(pdb_dir)\n",
    "print(len(files))\n",
    "\n",
    "out_dir = '../pdb_chains_new'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for file in tqdm(files):\n",
    "    split_pdb_by_chains(f'{pdb_dir}/{file}', out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15385/15385 [03:22<00:00, 75.96it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pdb_dir = '../data_preparation/pdb_test_06May_merged'\n",
    "files = os.listdir(pdb_dir)\n",
    "print(len(files))\n",
    "\n",
    "out_dir = '../pdb_chains_new'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for file in tqdm(files):\n",
    "    split_pdb_by_chains(f'{pdb_dir}/{file}', out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('../pdb_chains_new_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:17<00:00, 19.57it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "desc_dir = '../descriptors_test_2'\n",
    "des_files = os.listdir(desc_dir)\n",
    "\n",
    "import shutil\n",
    "\n",
    "out = '../masif_descriptors_test/'\n",
    "if not os.path.exists(out):\n",
    "    os.makedirs(out)\n",
    "for file in tqdm(des_files):\n",
    "    left_name = file.split('_')[0] + '_' + file.split('_')[1]\n",
    "    right_name = file.split('_')[0] + '_' + file.split('_')[2]\n",
    "    if not os.path.exists(os.path.join(out, left_name)):\n",
    "        os.makedirs(os.path.join(out, left_name))\n",
    "    if not os.path.exists(os.path.join(out, right_name)):\n",
    "        os.makedirs(os.path.join(out, right_name))\n",
    "    shutil.copy(os.path.join(desc_dir, file, 'p1_desc_flipped.npy'), os.path.join(out, left_name, 'desc_flipped.npy'))\n",
    "    shutil.copy(os.path.join(desc_dir, file, 'p1_desc_straight.npy'), os.path.join(out, left_name, 'desc_straight.npy'))\n",
    "    shutil.copy(os.path.join(desc_dir, file, 'p2_desc_flipped.npy'), os.path.join(out, right_name, 'desc_flipped.npy'))\n",
    "    shutil.copy(os.path.join(desc_dir, file, 'p2_desc_straight.npy'), os.path.join(out, right_name, 'desc_straight.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6757/6757 [05:23<00:00, 20.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "desc_dir = '../sc05/good_descriptors_negatives_06may'\n",
    "des_files = os.listdir(desc_dir)\n",
    "\n",
    "import shutil\n",
    "\n",
    "out = '../masif_descriptors'\n",
    "if not os.path.exists(out):\n",
    "    os.makedirs(out)\n",
    "for file in tqdm(des_files):\n",
    "    left_name = file.split('_')[0] + '_' + file.split('_')[1]\n",
    "    right_name = file.split('_')[0] + '_' + file.split('_')[2]\n",
    "    if not os.path.exists(os.path.join(out, left_name)):\n",
    "        os.makedirs(os.path.join(out, left_name))\n",
    "    if not os.path.exists(os.path.join(out, right_name)):\n",
    "        os.makedirs(os.path.join(out, right_name))\n",
    "    shutil.copy(os.path.join(desc_dir, file, 'p1_desc_flipped.npy'), os.path.join(out, left_name, 'desc_flipped.npy'))\n",
    "    shutil.copy(os.path.join(desc_dir, file, 'p1_desc_straight.npy'), os.path.join(out, left_name, 'desc_straight.npy'))\n",
    "    shutil.copy(os.path.join(desc_dir, file, 'p2_desc_flipped.npy'), os.path.join(out, right_name, 'desc_flipped.npy'))\n",
    "    shutil.copy(os.path.join(desc_dir, file, 'p2_desc_straight.npy'), os.path.join(out, right_name, 'desc_straight.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7193/7193 [06:25<00:00, 18.65it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "desc_dir = '../sc05/good_descriptors_positives_06may'\n",
    "des_files = os.listdir(desc_dir)\n",
    "\n",
    "import shutil\n",
    "\n",
    "out = '../masif_descriptors/'\n",
    "if not os.path.exists(out):\n",
    "    os.makedirs(out)\n",
    "for file in tqdm(des_files):\n",
    "    left_name = file.split('_')[0] + '_' + file.split('_')[1]\n",
    "    right_name = file.split('_')[0] + '_' + file.split('_')[2]\n",
    "    if not os.path.exists(os.path.join(out, left_name)):\n",
    "        os.makedirs(os.path.join(out, left_name))\n",
    "    if not os.path.exists(os.path.join(out, right_name)):\n",
    "        os.makedirs(os.path.join(out, right_name))\n",
    "    shutil.copy(os.path.join(desc_dir, file, 'p1_desc_flipped.npy'), os.path.join(out, left_name, 'desc_flipped.npy'))\n",
    "    shutil.copy(os.path.join(desc_dir, file, 'p1_desc_straight.npy'), os.path.join(out, left_name, 'desc_straight.npy'))\n",
    "    shutil.copy(os.path.join(desc_dir, file, 'p2_desc_flipped.npy'), os.path.join(out, right_name, 'desc_flipped.npy'))\n",
    "    shutil.copy(os.path.join(desc_dir, file, 'p2_desc_straight.npy'), os.path.join(out, right_name, 'desc_straight.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pdb_files = set([x[:-len('.pt')] for x in os.listdir('../masif_features/processed')])\n",
    "desc_files = [x for x in os.listdir('../masif_features/processed/masif_descriptors')]\n",
    "# desc_files = []\n",
    "# for file in desc_files_tmp:\n",
    "#     if len(os.listdir(os.path.join('../masif_features/processed/masif_descriptors', file))) > 0:\n",
    "#         desc_files.append(file)\n",
    "\n",
    "# desc_files = set(desc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generate_file(first, second, label, path):\n",
    "    good_ids = []\n",
    "    for i in range(len(first)):\n",
    "        if first[i] in pdb_files and second[i] in pdb_files and first[i] in desc_files and second[i] in desc_files:\n",
    "            good_ids.append(i)\n",
    "    data = [['', '', first[i], '', '', second[i], label[i]] for i in good_ids]\n",
    "    print(f'took {len(data)} out of {len(first)}')\n",
    "    np.random.shuffle(data)\n",
    "    data = np.array(data, dtype='<U12')\n",
    "    np.save(path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../test_final_pairs_labels.txt', sep='\\t')\n",
    "\n",
    "first = df.pair.apply(lambda x: '_'.join(x.split('_')[:2])).to_list()\n",
    "second = df.pair.apply(lambda x: x.split('_')[0] + '_' + x.split('_')[2]).to_list()\n",
    "label = df.label.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ids = list(range(len(first)))\n",
    "first_val, first_test, second_val, second_test, label_val, label_test = train_test_split(first, second, label, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 7682 out of 7693\n",
      "took 7680 out of 7692\n"
     ]
    }
   ],
   "source": [
    "generate_file(first_test, second_test, label_test, '../masif_features/testset.npy')\n",
    "generate_file(first_val, second_val, label_val, '../masif_features/valset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 13911 out of 13950\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../labels_goods_06May.txt', sep='\\t', header=None)\n",
    "\n",
    "first = df[0].apply(lambda x: '_'.join(x.split('_')[:2])).to_list()\n",
    "second = df[0].apply(lambda x: x.split('_')[0] + '_' + x.split('_')[2]).to_list()\n",
    "label = df[1].to_list()\n",
    "\n",
    "generate_file(first, second, label, '../masif_features/trainset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pdb_files = set([x[:-len('.pt')] for x in os.listdir('../masif_features/processed')])\n",
    "desc_files = [x for x in os.listdir('../masif_features/processed/masif_descriptors')]\n",
    "\n",
    "import numpy as np\n",
    "def generate_file(first, second, label, path):\n",
    "    good_ids = []\n",
    "    for i in range(len(first)):\n",
    "        if first[i] in pdb_files and second[i] in pdb_files and first[i] in desc_files and second[i] in desc_files:\n",
    "            good_ids.append(i)\n",
    "    data = [['', '', first[i], '', '', second[i], label[i]] for i in good_ids]\n",
    "    print(f'took {len(data)} out of {len(first)}')\n",
    "    np.random.shuffle(data)\n",
    "    data = np.array(data, dtype='<U12')\n",
    "    np.save(path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../test_final_pairs_labels.txt', sep='\\t')\n",
    "\n",
    "first = df.pair.apply(lambda x: '_'.join(x.split('_')[:2])).to_list()\n",
    "second = df.pair.apply(lambda x: x.split('_')[0] + '_' + x.split('_')[2]).to_list()\n",
    "label = df.label.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ids = list(range(len(first)))\n",
    "first_val, first_test, second_val, second_test, label_val, label_test = train_test_split(first, second, label, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 384 out of 385\n",
      "took 385 out of 385\n"
     ]
    }
   ],
   "source": [
    "generate_file(first_test[::20], second_test[::20], label_test[::20], '../masif_features/testset_small.npy')\n",
    "generate_file(first_val[::20], second_val[::20], label_val[::20], '../masif_features/valset_small.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 697 out of 698\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../labels_goods_06May.txt', sep='\\t', header=None)\n",
    "\n",
    "first = df[0].apply(lambda x: '_'.join(x.split('_')[:2])).to_list()\n",
    "second = df[0].apply(lambda x: x.split('_')[0] + '_' + x.split('_')[2]).to_list()\n",
    "label = df[1].to_list()\n",
    "\n",
    "generate_file(first[::20], second[::20], label[::20], '../masif_features/trainset_small.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pdb_files = set([x[:-len('.pt')] for x in os.listdir('../masif_test/processed')])\n",
    "desc_files = [x for x in os.listdir('../masif_test/processed/masif_descriptors')]\n",
    "# desc_files = []\n",
    "# for file in desc_files_tmp:\n",
    "#     if len(os.listdir(os.path.join('../masif_features/processed/masif_descriptors', file))) > 0:\n",
    "#         desc_files.append(file)\n",
    "\n",
    "# desc_files = set(desc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 351 out of 351\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../test_2_labels.txt', sep='\\t')\n",
    "\n",
    "first = df['pair'].apply(lambda x: '_'.join(x.split('_')[:2])).to_list()\n",
    "second = df['pair'].apply(lambda x: x.split('_')[0] + '_' + x.split('_')[2]).to_list()\n",
    "label = df['label'].to_list()\n",
    "\n",
    "generate_file(first, second, label, '../masif_test/testset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
